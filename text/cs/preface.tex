\pagestyle{plain}
\setcounter{page}{1}

\chapter{Úvod}
Hlavní motivací pro výběr této práce byl vysoký nárůst v poptávce na strojové zpracovávání dat. Velký důraz je kladen na rychlost a efektivitu výpočtu, kde se můžeme často setkat s požadavky na okamžité zpracování velkého objemu dat.
Pokud pro takovéto úlohy využijeme moderní počítačové čipy, které podporují paralelní výpočty, můžeme výpočet zjednodušit rozdělením na menší nezávislé podúlohy, které lze pak řešit najednou. Hlavní problémem je právě toto rozdělení dat. Různé algoritmy totiž vyžadují různé rozdělení dat a mnohdy závisí i na vlastnostech vstupních dat. Tuto problematiku je tedy nutné prozkoumat detailněji.\\
%The main motivations for choosing this topic was a great growth in demands on machine computing. Especially, demands on computation time and amount of work are a challenge, because there are needs for in-time processing of huge volumes of data. %With utilization of modern chips supporting parallel computations, this problem is very often solved by splitting basic algorithms into independent tasks and computing them concurrently. Problem is that the decomposition of algorithms into parallel tasks is %usually hard and needs further research.

V této práci se zaměříme na možnosti zlepšení shlukové analýzy pomocí efektivní implementace pro paralelní architektury jako například vícejádrové počítačové (CPU) a grafické (GPU) čipy. Budeme se zabývat především různými přístupy k paralelizaci algoritmu a závislosti na vlastnostech vstupních dat.
Data pochází z mnoha různých zdrojů jako například sociální sítě, finanční burzy, lékařské pozorování, průzkum vesmíru a mnoho dalších. I když jsou data velmi odlišná, mají jedno společné. Obsahují velmi užitečná data pro vědce, sociology, lékaře ale i pro analytiky, makléře a například i pro reklamu.
Pokud se nám podaří urychlit shlukovou analýzu paralelizací výpočtu, budeme moci řešit problémy mnohem rychleji, což je pro některé odvětví zásadní. Naše řešení může dokonce zavést shlukovou analýzu i do odvětví, ve kterých byla dříve nepoužitelná ať už kvůli rychlosti výpočtu a nebo velkému objemu dat.\\

%In this thesis, we are exploring the possibilities of improving the cluster analysis by effective implementation of its algorithm on parallel architectures like multicore CPUs and GPUs. Mainly, we are investigating different parallelization approaches and their %dependence on the input data properties in centroid based clustering.
%The data are collected from many sources such as social networks, financial markets, medical observation, space exploration and many others. Even if the data comes from different sources, they have something in common. They contain useful %informations for scientists, sociologist, medics, but even for business analysts, brokers, or for advertisement.
%If we are able to parallelize the cluster analysis, we can solve problems with its runtime performance, which is a concern as data are growing rapidly. Our solution could make cluster analysis usable in areas where basic algorithms was inappropriate due %to specific demands on computation performance and/or data size.\\

%, especially when finding the correct parameter K can only be done by performing several runs with different numbers of clusters and initial seeds~\cite{Zechner09}.\\
%Clustering data from the mentioned sources has a challenge - data are simply too large and processing them could take an unbearable amount of time. This problem could be solved by parallelization, but especially on common hardware, it may not be enough. 

Protože shluková analýza zahrnuje spoustu možných přístupů, musíme si vybrat jeden konkrétní algoritmus, který budeme následně analyzovat. Pro tuto práci jsme zvolil algoritmus k-means především pro jeho široké využití, nízkou složitost a dobře známé matematické vlastnosti. Také jde o jeden z nejefektivnějších shlukových algoritmů zmiňovaných v literatuře~\cite{Aggarwal13}.\\
%If we focus on the parallelization of the centroid based clustering, we must pick a particular algorithm for the analysis. As a representative, we chose the k-means algorithm, because it is widely used for its low complexity and well understood mathematical properties. It is also one of the most efficient clustering algorithms proposed in the %literature of data clustering~\cite{Aggarwal13}.\\

Algoritmus k-means můžeme definovat následovně: Vstupem je množina bodů a počet shluků $k$. Úkolem algoritmu je seskupit body do nepřekrývajících se shluků. Každý takový shluk navíc obsahuje speciální bod zvaný centroid, který je zkonstruován jako průměr ze všech bodů, pro které je tento centroid nejblíže ze všech. K výpočtu vzdálenosti lze použít datům odpovídající metriku, nejčastěji se však využívá Eukleidovská vzdálenost~\cite{Zechner09}. Optimální množinu centroidů lze nalézt tak, že se snažíme minimalizovat součet vzdáleností mezi jednotlivými body a průměrem v daném shluku, která je reprezentován právě nejbližším centroidem. Je dokázáno, že vyřešit tento problém je NP-těžké už pro 2 shluky~\cite{Drineas04}. K-means optimální řešení pouze aproximuje postupnou konvergencí k lokálnímu minimu, které závisí na počátečních centroidech.\\

%The k-means clustering could be defined as follows: a set of points and a number of clusters $k$ are given. We need to group points into non-overlapping clusters with special point called centroid. This cluster is composed as a mean of all points for which cluster centroid is the nearest centroid using appropriate metric, usually the Euclidean %distance~\cite{Zechner09}. The optimal set of centroids can be found by by minimizing the sum of distances between points and a mean of the enclosing cluster represented by the closest centroid. Solving this optimization problem was proven to be NP-hard even for two clusters~\cite{Drineas04}, however, k-means approximate the %optimal solution by converging to a local minimum of previously described minimization problem depending on the initial centroids~\cite{Bottou95}.\\

Prvním krokem algoritmu k-means je výběr $k$ bodů, které poslouží jako počáteční centroidy. Velmi často se k tomuto účelu volí náhodné body ze vstupní množiny. V dalším kroku je pak každý bod přiřazen k nejbližšímu centroidu. Poté se pro nově vzniklé shluky spočítá nový centroid jako průměr obsažených bodů. Algoritmus pracuje iterativně opakováním těchto dvou kroků dokud se centroidy neustálí (nezmění se mezi dvěma iteracemi) a nebo pokud není dosaženo předem určeného počtu iterací.\\

%K-means algorithm starts by choosing K points as a initial centroids. Usually, random points from the input set are used. This phase is known as the seeding stage.
%Then, in the labeling stage, each point is assigned to the nearest centroid.
%When clusters are formed, the centroid for each cluster is updated.
%Algorithm works iteratively by repeating the labeling and the update stage until centroids does not change between two iterations or after a given number of iterations.\\

Protože je algoritmus tvořen mnoha datově paralelními úlohami, je dobré výpočetní prostředky, které jsou schopny této vlastnosti využít.
Dobrým kandidátem pro paralelizaci k-means jsou grafické karty~\cite{Zechner09} jakožto levné, masivně paralelní procesory. Obsahují tisíce jednoduchých jader, které jsou schopné počítat základní matematické operace. I přesto, že jejich hlavním zaměřením jsou primárně grafické úlohy, jsou tyto karty schopné poskytnout svůj výpočetní výkon i pro obecné úlohy (General-purpose computing on graphics processing units - GPGPU). Pokud se nám tedy podaří využít potenciálu grafických karet a zároveň datového paralelismu v algoritmu k-means k rovnoměrnému rozdělení výpočtů mezi jednotliví výpočetní jádra GPU, budeme schopni výpočet mnohonásobně zrychlit.\\

%Because the k-means algorithm is composed of many data parallel tasks, we should use hardware, which could take advantage of this attribute.
%One of the best candidates for the parallelization of k-means are graphics cards~\cite{Zechner09} as a low-cost, highly parallel streaming processor. They contains thousands of simple cores capable of general math operations. Even though their purpose is primarily computations of graphical tasks, these cards also allow to use theirs %computing performance for general purpose computations (GPGPU).
%If we use potential of GPU for k-means algorithm, we can use the data parallelism in k-means algorithm and divide the work among all cores and make the computation much faster. For example, we can compute the nearest centroid for each point in parallel and utilize all available cores.\\
 
%   Their performance with each generation increases rapidly so they are a great opportunity for making current compute-intensive algorithmic problems efficient and less time-consuming.\\
Paralelizace algoritmu k-means ale přináší i úskalí, která je potřeba vyřešit. Algoritmus musí být optimalizován pro masivně paralelní prostředí. To především znamená, že musíme být schopni jednotlivé úkoly rovnoměrně rozdělit mezi tisíce výpočetních jader a postarat se o jejich efektivní využití. Pokud by se nám nepodařilo zapojit všechna dostupná jádra, ztratili bychom velké množství výkonu, což je samozřejmě nežádoucí. Další výzvou je pak co nejefektivnější využití paměťového modelu grafických karet, protože špatné používání paměti, jako například časté přístupy k nejpomalejším pamětím, mohou výkon algoritmu rapidně snížit.\\

%Parallelization of k-means algorithm on GPU brings also some challenges. We must optimize the algorithm to massively parallel environment. This means that the work must be divided between thousands of computing cores and we must take care of their effective load balancing, because we could loose a lot of performance when only part of all available cores are utilized. Also the memory usage must be designed to fit the GPU memory model because we will loose many time by waiting for memory access to slower memories.\\

%If we omit general parallelization issues such as synchronization and non-parallelizable parts of algorithm, we must also challenge new problems arising from a different parallelization environment. 

V roce 2009 již zkoumal využití grafických karet pro algoritmus k-means Hong-Tao Bai~\cite{Hong09}, ale tato práce byla spíše konceptem a neprozkoumala detailní možnosti paralelizace.
V naší práci se budeme soustředit na vlastnosti vstupních dat a jejich vliv na výkonnost algoritmu při odlišných přístupech k paralelizaci. Tento vztah je pro k-means rozhodující, protože právě vstupní data velice ovlivňují výpočet algoritmu a tím pádem i jeho efektivitu.
Dalším důvodem je pak velice rychlý vývoj technologií, tedy i grafických karet, které se od roku 2009 v mnohém posunuly kupředu, takže bychom se chtěli zaměřit i na výkon jednotlivých generací karet.\\

%The conversion of k-means algorithm to GPU was already introduced in 2009 by Hong-Tao Bai et al.~\cite{Hong09}. However, their work does not explore detailed possibilities of parallelization.
%In this thesis, we are analyzing the input data properties and their impact on the computing performance at different approaches to the k-means parallelization. This is very crucial for this algorithm, which execution is highly affected by the input data that could vary greatly.\\

%Also, because of a rapid development of GPGPU technologies and GPUs itself, we want to explore new GPU possibilities provided by the current hardware.\\

% TODO - k-means specific properties - input types

%Problem is that the data amount grows sometimes even faster than compute performance of the most modern hardware so neither computers have enough processing power for processing this data when we use standard algorithms. For this purposes there are known technologies for processing or simplifying big data including cluster analysis, generic algorithms, machine learning or simulation.
%Problem is that in modern big data world neither of these techniques in conjunction with traditional hardware are enough so we are enforced to use other possibilities. \\
%Because processing single item is not so complex and processing them is very often independent, ideal hardware should contain many of simple and cheap compute units capable of parallel operations on huge amount of data. Luckily, this is the way followed by manufacturers of the most modern hardware, which is not designed only for the highest performance of individual cores but also for the best parallel cooperative work reached by increasing the number of cores on single chip and speeding up the communication between cores. \\

%A reasonable solution is to use compute performance of graphics cards which contains thousands of simple cores. Even though their purpose is primarily graphical tasks, cards allows to use theirs power to common computations (general-purpose computing on graphics processing units - GPGPU). Their performance with each generation increases rapidly so they are great opportunity for making current compute-intensive algorithmic problems efficient and less time-consuming and make them usable for areas in which their application was inefficient or even not possible.\\
%Because graphical cards was originally specialized for computation of graphical primitives, whose contain many of separate and independent tasks, the problem is when we need to process tasks that are not so similar to graphical primitives. This is usually the problem of processing big data in some more sophisticated way and we must solve the problem by adding additional dependencies between computations. \\



%Parallelizing this algorithm contains several problems. The first thing is that we must solve race conditions, for example, when new centroids are computed from newly assigned objects. The new value of centroid is computed as a mean from all object assigned to same centroid so we need to accumulate all these objects in single variable from different threads and this could be the problem.\\

%Problem is that this algorithm contains several compute and data dependencies which must be solved. We could easily compute the nearest representative for each object but problem is when we want new representatives for the next step based on newly assigned objects. Because we have a large number of objects and a large number of compute cores, we want to parallelize the computation so each object is processed by single core. Problem is that we need to accumulate data for each of emerging representatives and the problem is, that it could be accessed by many cores at a time. We must choose some synchronization primitive which slows down the computation, or choose a different way of parallelizing this task such as parallelizing the computation in representative manner - each new representative is processed by single compute core and it iterates through all objects which could be slow too, because we could not have so many clusters as compute cores.\\

%There are also problems with data size and memory usage efficiency. GPU has several types of memory. They differ significantly in size and latency - bigger memory is usually slower with bigger latency and vice versa, smaller memory is faster with small latency times. The main goal is to use the memory as effectively as possible. Problem is that the big input data are sometimes much larger than the biggest GPU memory so we must design a way, how to swap data between host and GPU and between GPU's memory effectively. This is problem because of variety of input data so we must try several versions and find out which approach is the best with respect to the different input data.\\

%We must solve this by modification of the k-means algorithm to GPU environment and develop several versions to find out which approach fits the best for concrete type of data.

%contributions
%We will focus on different approaches to GPGPU parallelization of k-means algorithm and impacts of different data types on performance. We tried to utilize the data properties for designing different algorithm versions and investigated which version performs better on specific data by comparing versions on all data types.\\
%outline

\hyperref[sec:clusteranalysis]{Kapitola~\ref*{sec:clusteranalysis}} obsahuje úvod do shlukové analýzy, různé druhy modelů shluků a shlukových algoritmů. \hyperref[sec:gpgpu]{Kapitola~\ref*{sec:gpgpu}} se zabývá GPGPU, CUDA frameworkem a jeho analýzou. \hyperref[sec:implementation]{Kapitola~\ref*{sec:implementation}} obsahuje popis a analýzu naší implementace a paralelizačních metod. V \hyperref[sec:results]{kapitole~\ref*{sec:results}} je pak rozbor dosažených výsledků této práce a efektivity paralelizace k-means.

%The \hyperref[sec:clusteranalysis]{Chapter~\ref*{sec:clusteranalysis}} introduce cluster analysis, several types of cluster models and clustering algorithms. The \hyperref[sec:gpgpu]{Chapter~\ref*{sec:gpgpu}} concerns GPGPU, CUDA framework and its analysis. The \hyperref[sec:implementation]{Chapter~\ref*{sec:implementation}} consists of the description of our implementations and used parallelization methods and in the \hyperref[sec:results]{Chapter~\ref*{sec:results}}, we will discuss the results of this thesis and efficiency of k-means parallelization. 