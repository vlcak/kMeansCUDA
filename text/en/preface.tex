\pagestyle{plain}
\setcounter{page}{1}

\chapter{Introduction}
In the modern era, demands on machine computing grows rapidly. Especially, demands on computation time and amount of work are a concern, because people want usually in-time processing of huge volumes of data. This problem is very often solved by splitting basic algorithms into independent tasks and compute them simultaneously.\\
Nowadays, chips that support parallel computations are almost everywhere, starting from the wearable smart watches to highly specialized computing clusters in datacenters. We would like to take the advantage of this opportunity and explore the parallelization on the common, low-cost hardware.\\

In this thesis, we are exploring the possibilities of improving the cluster analysis by effective implementation of the cluster analysis algorithm on parallel architectures like multicore CPUs and GPUs. Mainly, we are investigating different parallelization approaches and their dependence on the input data properties in centroid based clustering.\\
The main motivations for choosing this topic was a great growth in demand for processing large data. The data are collected from many sources such as social networks, financial markets, medical observation, space exploration and many others. Even if the data comes from different sources, they have something in common. They contain useful informations for scientists, sociologist, medics, but even for business analysts, brokers, or for advertisement. \\
%Clustering data from the mentioned sources has a challenge - data are simply too large and processing them could take an unbearable amount of time. This problem could be solved by parallelization, but especially on common hardware, it may not be enough. 

If we focus on the parallelization of the centroid based clustering, we must pick a particular algorithm for the analysis. As a representative, we chose the k-means algorithm~\cite{EstivillCastro02}, because it is widely used for its low complexity and well understood mathematical properties~\cite{Zechner09}. It is also one of the most efficient clustering algorithms proposed in the literature of data clustering~\cite{Aggarwal13}.\\
Parallelization of k-means is very useful, because the runtime performance of the algorithm is a concern as data are growing rapidly, especially when finding the correct parameter K can only be done by performing several runs with different numbers of clusters and initial seeds~\cite{Zechner09}.\\

The k-means task could be defined as follows: a set of points and a number of clusters are given. We need to split points into non-overlapping clusters so that each cluster contains special point called centroid. This cluster is composed of all points for which cluster centroid is the nearest centroid using appropriate metric, usually the Euclidean distance~\cite{Zechner09}. The optimal set of centroids can be found by by minimizing the sum of distances between points and their closest centroid. Solving this optimization problem was proven to be NP-hard even for two clusters~\cite{Drineas04}, however, k-means only approximate the optimal solution by converging to a local minimum of described function depending on the initial centroids~\cite{Bottou95}. \\

K-means algorithm starts by choosing random K points from the input set as the initial centroids. This phase is known as the seeding stage.
Then, in the labeling stage, each point is assigned to the nearest centroid based on a particular proximity measure chosen.
When clusters are formed, the centroid for each cluster is updated in the update stage.
Algorithm works iteratively by repeating the labeling and the update stage until centroids does not change between two iterations or after a given number of steps.\\

Because processing single item in the k-means algorithm is not so complex and the computation is independent very often (for example finding the nearest cluster), an ideal hardware should contain many simple compute units capable of parallel operations on huge amount of data. Because of a small number of complex cores on CPUs, we should look for some specific hardware, which better reflects demands specified before.\\
One of the best candidates for the parallelization of k-means are graphics cards as a low-cost, highly parallel streaming co-processor. They contains thousands of simple cores capable of basic math operations~\cite{Zechner09}. Even though their purpose is primarily computations of graphical tasks, these cards also allow to use theirs computing performance also for non-graphical computations (known as general-purpose computing on graphics processing units - GPGPU). Their performance with each generation increases rapidly so they are a great opportunity for making current compute-intensive algorithmic problems efficient and less time-consuming.\\

Parallelization of serial algorithms on GPU brings also some problems. If we omit general parallelization problems such as synchronization and non-parallelizable parts of algorithm, we must also challenge new problems arising from a different parallelization environment. At first, not all algorithms are good for GPU parallelization. Algorithms, which have irregular memory access patterns are hard to parallelize on GPU, because we can not effectively use GPU memory caches. Also problems, which not have high arithmetic intensity, make GPU parallelization inefficient, because we can not use all GPU computing power.\\
The other problem is that we must optimize the algorithm to different environment. This means that we must divide the work between thousands of computing cores and optimize memory access to an efficient use of caches.\\

The conversion of k-means algorithm to GPU was already introduced in 2009~\cite{Hong09}. However, this work does not explore detailed possibilities of parallelization.\\
In this thesis, we are analyzing the input data properties and their impact on the computing performance at different approaches to the k-means parallelization. This is very interesting for this algorithm, which is highly affected by the input data that varies greatly. \\
Also, because of a rapid development of GPGPU technologies and GPUs itself, we want to explore new GPU possibilities provided by the current hardware.\\

% TODO - k-means specific properties - input types

%Problem is that the data amount grows sometimes even faster than compute performance of the most modern hardware so neither computers have enough processing power for processing this data when we use standard algorithms. For this purposes there are known technologies for processing or simplifying big data including cluster analysis, generic algorithms, machine learning or simulation.
%Problem is that in modern big data world neither of these techniques in conjunction with traditional hardware are enough so we are enforced to use other possibilities. \\
%Because processing single item is not so complex and processing them is very often independent, ideal hardware should contain many of simple and cheap compute units capable of parallel operations on huge amount of data. Luckily, this is the way followed by manufacturers of the most modern hardware, which is not designed only for the highest performance of individual cores but also for the best parallel cooperative work reached by increasing the number of cores on single chip and speeding up the communication between cores. \\

%A reasonable solution is to use compute performance of graphics cards which contains thousands of simple cores. Even though their purpose is primarily graphical tasks, cards allows to use theirs power to common computations (general-purpose computing on graphics processing units - GPGPU). Their performance with each generation increases rapidly so they are great opportunity for making current compute-intensive algorithmic problems efficient and less time-consuming and make them usable for areas in which their application was inefficient or even not possible.\\
%Because graphical cards was originally specialized for computation of graphical primitives, whose contain many of separate and independent tasks, the problem is when we need to process tasks that are not so similar to graphical primitives. This is usually the problem of processing big data in some more sophisticated way and we must solve the problem by adding additional dependencies between computations. \\



%Parallelizing this algorithm contains several problems. The first thing is that we must solve race conditions, for example, when new centroids are computed from newly assigned objects. The new value of centroid is computed as a mean from all object assigned to same centroid so we need to accumulate all these objects in single variable from different threads and this could be the problem.\\

%Problem is that this algorithm contains several compute and data dependencies which must be solved. We could easily compute the nearest representative for each object but problem is when we want new representatives for the next step based on newly assigned objects. Because we have a large number of objects and a large number of compute cores, we want to parallelize the computation so each object is processed by single core. Problem is that we need to accumulate data for each of emerging representatives and the problem is, that it could be accessed by many cores at a time. We must choose some synchronization primitive which slows down the computation, or choose a different way of parallelizing this task such as parallelizing the computation in representative manner - each new representative is processed by single compute core and it iterates through all objects which could be slow too, because we could not have so many clusters as compute cores.\\

%There are also problems with data size and memory usage efficiency. GPU has several types of memory. They differ significantly in size and latency - bigger memory is usually slower with bigger latency and vice versa, smaller memory is faster with small latency times. The main goal is to use the memory as effectively as possible. Problem is that the big input data are sometimes much larger than the biggest GPU memory so we must design a way, how to swap data between host and GPU and between GPU's memory effectively. This is problem because of variety of input data so we must try several versions and find out which approach is the best with respect to the different input data.\\

%We must solve this by modification of the k-means algorithm to GPU environment and develop several versions to find out which approach fits the best for concrete type of data.

%contributions
%We will focus on different approaches to GPGPU parallelization of k-means algorithm and impacts of different data types on performance. We tried to utilize the data properties for designing different algorithm versions and investigated which version performs better on specific data by comparing versions on all data types.\\
%outline
The first chapter introduce cluster analysis, several types of cluster models and clustering algorithms. The next chapter concerns GPGPU, CUDA framework and its analysis. The third chapter consists of the description of our implementations and used parallelization methods and in the last chapter, we will discuss the results of this thesis and efficiency of k-means parallelization. 